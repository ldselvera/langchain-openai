{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd946a93-19e9-4316-b477-adde0e802ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\~andas'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-pinecone 0.0.3 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.2.38 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -qU langchain langchain-openai langchain-community langchain-experimental pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f555e0-165c-4133-8c1f-330649ee9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# Using LangSmith is recommended but not required. Uncomment below lines to use.\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da261d6-300f-4817-9566-a5ec22358742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv -O titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8b2bfa-daa4-423b-bed5-367d59df87c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887, 8)\n",
      "['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d5edc-d55c-4769-b756-85ec63d52c3c",
   "metadata": {},
   "source": [
    "## SQL\n",
    "Using SQL to interact with CSV data is the recommended approach because it is easier to limit permissions and sanitize queries than with arbitrary Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de15ea24-ac8a-4e77-b542-7a343bc88de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_23740\\6739636.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df.to_sql('titanic', connection, index=False, if_exists='append')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///titanic.db\")\n",
    "connection = engine.raw_connection()\n",
    "df.to_sql('titanic', connection, index=False, if_exists='append')\n",
    "# df.to_sql(\"titanic\", engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8257c4fe-03f2-4b1b-8999-6e13556a67ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['titanic']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 2, 'Master. Alden Gates Caldwell', 'male', 0.83, 0, 2, 29.0), (0, 3, 'Master. Eino Viljami Panula', 'male', 1.0, 4, 1, 39.6875), (1, 3, 'Miss. Eleanor Ileen Johnson', 'female', 1.0, 1, 1, 11.1333), (1, 2, 'Master. Richard F Becker', 'male', 1.0, 2, 1, 39.0), (1, 1, 'Master. Hudson Trevor Allison', 'male', 0.92, 1, 2, 151.55), (1, 3, 'Miss. Maria Nakid', 'female', 1.0, 0, 2, 15.7417), (0, 3, 'Master. Sidney Leonard Goodwin', 'male', 1.0, 5, 2, 46.9), (1, 3, 'Miss. Helene Barbara Baclini', 'female', 0.75, 2, 1, 19.2583), (1, 3, 'Miss. Eugenie Baclini', 'female', 0.75, 2, 1, 19.2583), (1, 2, 'Master. Viljo Hamalainen', 'male', 0.67, 1, 1, 14.5), (1, 3, 'Master. Bertram Vere Dean', 'male', 1.0, 1, 2, 20.575), (1, 3, 'Master. Assad Alexander Thomas', 'male', 0.42, 0, 1, 8.5167), (1, 2, 'Master. Andre Mallet', 'male', 1.0, 0, 2, 37.0042), (1, 2, 'Master. George Sibley Richards', 'male', 0.83, 1, 1, 18.75)]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = SQLDatabase(engine=engine)\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM titanic WHERE Age < 2;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f22381b-b93b-4908-9fbc-33f3c7814d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent_executor = create_sql_agent(llm, db=db, agent_type=\"openai-tools\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb5a9c52-222b-4d59-9e74-97164f50a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mtitanic\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'titanic'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE titanic (\n",
      "\t\"Survived\" INTEGER, \n",
      "\t\"Pclass\" INTEGER, \n",
      "\t\"Name\" TEXT, \n",
      "\t\"Sex\" TEXT, \n",
      "\t\"Age\" REAL, \n",
      "\t\"Siblings/Spouses Aboard\" INTEGER, \n",
      "\t\"Parents/Children Aboard\" INTEGER, \n",
      "\t\"Fare\" REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from titanic table:\n",
      "Survived\tPclass\tName\tSex\tAge\tSiblings/Spouses Aboard\tParents/Children Aboard\tFare\n",
      "0\t3\tMr. Owen Harris Braund\tmale\t22.0\t1\t0\t7.25\n",
      "1\t1\tMrs. John Bradley (Florence Briggs Thayer) Cumings\tfemale\t38.0\t1\t0\t71.2833\n",
      "1\t3\tMiss. Laina Heikkinen\tfemale\t26.0\t0\t0\t7.925\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT AVG(Age) AS Average_Age FROM titanic WHERE Survived = 1'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(28.408391812865496,)]\u001b[0m\u001b[32;1m\u001b[1;3mThe average age of survivors is approximately 28.41 years.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's the average age of survivors\",\n",
       " 'output': 'The average age of survivors is approximately 28.41 years.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what's the average age of survivors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5b5ec-757a-4007-abf0-92e776ecd36b",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "Instead of SQL we can also use data analysis libraries like pandas and the code generating abilities of LLMs to interact with CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99649380-93d8-414c-9be0-3b4b84aa48f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "df['Age'].corr(df['Fare'])\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "ai_msg = llm.invoke(\n",
    "    \"I have a pandas DataFrame 'df' with columns 'Age' and 'Fare'. Write code to compute the correlation between the two columns. Return Markdown for a Python code snippet and nothing else.\"\n",
    ")\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0db46776-de85-4d65-a422-e638d5faf6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.30542018038331"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "tool = PythonAstREPLTool(locals={\"df\": df})\n",
    "tool.invoke(\"df['Fare'].mean()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b061ff-395d-4652-aa35-e8e71ba19350",
   "metadata": {},
   "source": [
    "### function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d35f247-e2ef-47d8-bb76-84271ad56de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_OKodMRVz63rxGvmbhYoo0px4', 'function': {'arguments': '{\"query\":\"df[[\\'Age\\', \\'Fare\\']].corr()\"}', 'name': 'python_repl_ast'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 125, 'total_tokens': 139}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c7a78121-940d-4a85-98e1-2cce634789fc-0', tool_calls=[{'name': 'python_repl_ast', 'args': {'query': \"df[['Age', 'Fare']].corr()\"}, 'id': 'call_OKodMRVz63rxGvmbhYoo0px4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 125, 'output_tokens': 14, 'total_tokens': 139})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools([tool], tool_choice=tool.name)\n",
    "llm_with_tools.invoke(\n",
    "    \"I have a dataframe 'df' and want to know the correlation between the 'Age' and 'Fare' columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a790e65-916c-4db4-bb92-dea05d3a0ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"df[['Age', 'Fare']].corr()\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "\n",
    "parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)\n",
    "(llm_with_tools | parser).invoke(\n",
    "    \"I have a dataframe 'df' and want to know the correlation between the 'Age' and 'Fare' columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2390e683-95bd-4fd0-b2d3-06da5a40a2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|    |   Survived |   Pclass | Name                                               | Sex    |   Age |   Siblings/Spouses Aboard |   Parents/Children Aboard |    Fare |\\n|---:|-----------:|---------:|:---------------------------------------------------|:-------|------:|--------------------------:|--------------------------:|--------:|\\n|  0 |          0 |        3 | Mr. Owen Harris Braund                             | male   |    22 |                         1 |                         0 |  7.25   |\\n|  1 |          1 |        1 | Mrs. John Bradley (Florence Briggs Thayer) Cumings | female |    38 |                         1 |                         0 | 71.2833 |\\n|  2 |          1 |        3 | Miss. Laina Heikkinen                              | female |    26 |                         0 |                         0 |  7.925  |\\n|  3 |          1 |        1 | Mrs. Jacques Heath (Lily May Peel) Futrelle        | female |    35 |                         1 |                         0 | 53.1    |\\n|  4 |          0 |        3 | Mr. William Henry Allen                            | male   |    35 |                         0 |                         0 |  8.05   |'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "301a1a18-eb23-4901-9c51-a365b436d13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"df['Age'].corr(df['Fare'])\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = f\"\"\"You have access to a pandas dataframe `df`. \\\n",
    "Here is the output of `df.head().to_markdown()`:\n",
    "Given a user question, write the Python code to answer it. \\\n",
    "Return ONLY the valid Python code and nothing else. \\\n",
    "Don't assume you have access to any libraries other than built-in Python ones and pandas.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "code_chain = prompt | llm_with_tools | parser\n",
    "code_chain.invoke({\"question\": \"What's the correlation between age and fare\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f103d61-42b8-412c-bc51-0bd6c8d8898f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1123286369994162"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm_with_tools | parser | tool  # noqa\n",
    "chain.invoke({\"question\": \"What's the correlation between age and fare\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad94fe5-a173-4a2b-9811-bcc2af04ec39",
   "metadata": {},
   "source": [
    "## Conversational Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77f437d5-8177-4f07-bad7-9b698ec2d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "system = f\"\"\"You have access to a pandas dataframe `df`. \\\n",
    "Here is the output of `df.head().to_markdown()`:\n",
    "Given a user question, write the Python code to answer it. \\\n",
    "Don't assume you have access to any libraries other than built-in Python ones and pandas.\n",
    "Respond directly to the question once you have enough information to answer it.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system,\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "        # This MessagesPlaceholder allows us to optionally append an arbitrary number of messages\n",
    "        # at the end of the prompt using the 'chat_history' arg.\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def _get_chat_history(x: dict) -> list:\n",
    "    \"\"\"Parse the chain output up to this point into a list of chat history messages to insert in the prompt.\"\"\"\n",
    "    ai_msg = x[\"ai_msg\"]\n",
    "    tool_call_id = x[\"ai_msg\"].additional_kwargs[\"tool_calls\"][0][\"id\"]\n",
    "    tool_msg = ToolMessage(tool_call_id=tool_call_id, content=str(x[\"tool_output\"]))\n",
    "    return [ai_msg, tool_msg]\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(ai_msg=prompt | llm_with_tools)\n",
    "    .assign(tool_output=itemgetter(\"ai_msg\") | parser | tool)\n",
    "    .assign(chat_history=_get_chat_history)\n",
    "    .assign(response=prompt | llm | StrOutputParser())\n",
    "    .pick([\"tool_output\", \"response\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b02ede7c-5c0d-4455-bcb1-b59c99481dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_output':            Age      Fare\n",
       " Age   1.000000  0.112329\n",
       " Fare  0.112329  1.000000,\n",
       " 'response': 'The correlation between age and fare is approximately 0.1123.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What's the correlation between age and fare\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d35ba-c49f-4183-86dc-0008c6710a62",
   "metadata": {},
   "source": [
    "## Agent\n",
    "For complex questions it can be helpful for an LLM to be able to iteratively execute code while maintaining the inputs and outputs of its previous executions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6ab72e1-4511-442d-b83a-488ad1faeb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[['Age', 'Fare']].corr()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m           Age      Fare\n",
      "Age   1.000000  0.112329\n",
      "Fare  0.112329  1.000000\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[['Fare', 'Survived']].corr()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m              Fare  Survived\n",
      "Fare      1.000000  0.256179\n",
      "Survived  0.256179  1.000000\u001b[0m\u001b[32;1m\u001b[1;3mThe correlation between age and fare is 0.112, while the correlation between fare and survival is 0.256. Therefore, the correlation between fare and survival is greater than the correlation between age and fare.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the correlation between age and fare? is that greater than the correlation between fare and survival?\",\n",
       " 'output': 'The correlation between age and fare is 0.112, while the correlation between fare and survival is 0.256. Therefore, the correlation between fare and survival is greater than the correlation between age and fare.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "\n",
    "agent = create_pandas_dataframe_agent(llm, df, agent_type=\"openai-tools\", verbose=True, allow_dangerous_code=True)\n",
    "agent.invoke(\n",
    "    {\n",
    "        \"input\": \"What's the correlation between age and fare? is that greater than the correlation between fare and survival?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85c466-b0f2-4e4e-b19e-b384fd913089",
   "metadata": {},
   "source": [
    "## Multiple CSVs\n",
    "To handle multiple CSVs (or dataframes) we just need to pass multiple dataframes to our Python tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7729637-2fe6-4e99-b2c1-880e8a6a018a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1438499126295441"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df[[\"Age\", \"Fare\"]]\n",
    "df_2 = df[[\"Fare\", \"Survived\"]]\n",
    "\n",
    "tool = PythonAstREPLTool(locals={\"df_1\": df_1, \"df_2\": df_2})\n",
    "llm_with_tool = llm.bind_tools(tools=[tool], tool_choice=tool.name)\n",
    "df_template = \"\"\"```python\n",
    "{df_name}.head().to_markdown()\n",
    ">>> {df_head}\n",
    "```\"\"\"\n",
    "df_context = \"\\n\\n\".join(\n",
    "    df_template.format(df_head=_df.head().to_markdown(), df_name=df_name)\n",
    "    for _df, df_name in [(df_1, \"df_1\"), (df_2, \"df_2\")]\n",
    ")\n",
    "\n",
    "system = f\"\"\"You have access to a number of pandas dataframes. \\\n",
    "Here is a sample of rows from each dataframe and the python code that was used to generate the sample:\n",
    "\n",
    "{df_context}\n",
    "\n",
    "Given a user question about the dataframes, write the Python code to answer it. \\\n",
    "Don't assume you have access to any libraries other than built-in Python ones and pandas. \\\n",
    "Make sure to refer only to the variables mentioned above.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "\n",
    "chain = prompt | llm_with_tool | parser | tool\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"question\": \"return the difference in the correlation between age and fare and the correlation between fare and survival\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98264e-3a8f-430a-9136-988095534d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
