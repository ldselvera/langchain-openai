{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d65ceb",
   "metadata": {},
   "source": [
    "# Installing Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89ba9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3224f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3e1f9",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197c797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# llm.predict('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df87ec06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just a computer program, so I don't have feelings or emotions. But thank you for asking! How can I assist you today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chat_model.predict('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a933941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"What is the capital of France?\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict('What was my previous question?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd4b75",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21009f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How are you today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking! I have been processing a lot of information today and learning new things. How about you, how are you doing?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('How are you today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "693ec706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you today?\n",
      "AI: I'm doing well, thank you for asking! I have been processing a lot of information today and learning new things. How about you, how are you doing?\n",
      "Human: What was my previous question?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"How are you today?\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('What was my previous question?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b00466",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763a7bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['category'], template='\\nReturn all the subcategories of the following category\\n\\n{category}\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Return all the subcategories of the following category\n",
    "\n",
    "{category}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['category'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd070513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Return all the subcategories of the following category\n",
      "\n",
      "Machine Learning\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- Supervised Learning\\n- Unsupervised Learning\\n- Reinforcement Learning\\n- Deep Learning\\n- Natural Language Processing\\n- Computer Vision\\n- Clustering\\n- Classification\\n- Regression\\n- Dimensionality Reduction'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a07acc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\nYou are a helpful assistant who generate comma separated lists.\\nA user will only pass a category and you should generate subcategories of that category in a comma separated list.\\nONLY return comma separated and nothing more!\\n'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a helpful assistant who generate comma separated lists.\n",
    "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
    "ONLY return comma separated and nothing more!\n",
    "\"\"\"\n",
    "\n",
    "human_template = '{category}'\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    system_template\n",
    ")\n",
    "\n",
    "system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a03819ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['category'], template='{category}'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    human_template\n",
    ")\n",
    "\n",
    "human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce86e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning, Natural Language Processing, Computer Vision, Clustering, Classification, Regression'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message, human_message   \n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fe368",
   "metadata": {},
   "source": [
    "# Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b56d7eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Supervised Learning',\n",
       " 'Unsupervised Learning',\n",
       " 'Reinforcement Learning',\n",
       " 'Deep Learning',\n",
       " 'Natural Language Processing',\n",
       " 'Computer Vision',\n",
       " 'Clustering',\n",
       " 'Classification',\n",
       " 'Regression',\n",
       " 'Dimensionality Reduction']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaSeparatedParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        output = text.strip().split(',')\n",
    "        output = [o.strip() for o in output]\n",
    "        return output\n",
    "    \n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    output_parser=CommaSeparatedParser(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee909622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.331'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aa0f8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: food\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: country\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: colors\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': ['fruits', 'vegetables', 'dairy', 'grains', 'protein', 'snacks']},\n",
       " {'text': ['North America',\n",
       "   'South America',\n",
       "   'Europe',\n",
       "   'Asia',\n",
       "   'Africa',\n",
       "   'Oceania']},\n",
       " {'text': ['red',\n",
       "   'blue',\n",
       "   'green',\n",
       "   'yellow',\n",
       "   'orange',\n",
       "   'purple',\n",
       "   'pink',\n",
       "   'black',\n",
       "   'white',\n",
       "   'brown']}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {'category': 'food'},\n",
    "    {'category': 'country'},\n",
    "    {'category': 'colors'}\n",
    "]\n",
    "\n",
    "response = chain.apply(input_list)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "708f4719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[2]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efaa3e",
   "metadata": {},
   "source": [
    "# Simple Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea8f7e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"The Algorithm of Love\"'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_template = \"\"\"\n",
    "You are a writer. Given a subject, \n",
    "your job is to return a fun title for a play.\n",
    "\n",
    "Subject: {subject}\n",
    "Title:\"\"\"\n",
    "\n",
    "title_chain = LLMChain.from_string(\n",
    "    llm=chat_model,\n",
    "    template=title_template\n",
    ")\n",
    "\n",
    "title_chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33fa990e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In \"The Algorithm of Love,\" we follow the story of two unlikely individuals who find themselves connected through a dating app. As they navigate through the complexities of modern romance and the pressure to find love through technology, they begin to question if true love can really be found through an algorithm. Through a series of comedic and heartfelt moments, they discover that the key to finding love may not be in swiping right, but in taking a chance on something real. \"The Algorithm of Love\" explores the modern struggles of dating in a technology-driven world and the true meaning of connection and love.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synopsis_template = \"\"\"\n",
    "You are a writer. \n",
    "Given a title, write a synopsis for a play.\n",
    "\n",
    "Title: {title}\n",
    "Synopsis:\"\"\"\n",
    "\n",
    "synopsis_chain = LLMChain.from_string(\n",
    "    llm=chat_model,\n",
    "    template=synopsis_template\n",
    ")\n",
    "\n",
    "# title = \"The Algorithmic Adventure: A Machine Learning Marvel\"\n",
    "title = \"The Algorithm of Love\"\n",
    "\n",
    "\n",
    "synopsis_chain.run(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc9633b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Byte Me: A Machine Learning Comedy\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIn \"Byte Me: A Machine Learning Comedy\", audiences are taken on a hilarious journey into the world of artificial intelligence and machine learning. The play follows a group of tech-savvy friends who stumble upon a groundbreaking new algorithm that has the ability to predict human behavior with uncanny accuracy. As they test the limits of their creation, chaos ensues as the algorithm starts to develop a mind of its own and wreaks havoc on their lives. With witty dialogue, clever jokes, and unexpected twists, \"Byte Me\" explores the ethical dilemmas and absurdities of advanced technology in a light-hearted and entertaining way. Will the friends be able to outsmart their creation before it's too late, or will they be at the mercy of their own creation? Join us for a night of laughs and thought-provoking entertainment in \"Byte Me: A Machine Learning Comedy\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In \"Byte Me: A Machine Learning Comedy\", audiences are taken on a hilarious journey into the world of artificial intelligence and machine learning. The play follows a group of tech-savvy friends who stumble upon a groundbreaking new algorithm that has the ability to predict human behavior with uncanny accuracy. As they test the limits of their creation, chaos ensues as the algorithm starts to develop a mind of its own and wreaks havoc on their lives. With witty dialogue, clever jokes, and unexpected twists, \"Byte Me\" explores the ethical dilemmas and absurdities of advanced technology in a light-hearted and entertaining way. Will the friends be able to outsmart their creation before it\\'s too late, or will they be at the mercy of their own creation? Join us for a night of laughs and thought-provoking entertainment in \"Byte Me: A Machine Learning Comedy\".'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[title_chain, synopsis_chain],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbc90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
