{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0053445c-3375-496a-b6fd-4be1ca6ef1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install pypdf\n",
    "# %pip install chromadb\n",
    "# %pip install --upgrade chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff6d87-d6f3-42a5-bac7-eaf6d7f53ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = 'mixed_data/element_of_SL.pdf'\n",
    "\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "docs = loader.load_and_split()\n",
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb43610-0858-4be3-9d91-d0345564adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "index = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding = OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf6051-4fee-4ee8-81ae-10a2f7af2867",
   "metadata": {},
   "source": [
    "## Stuff strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15299e31-29ca-407c-8b27-710f19a36bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "100 3. Linear Methods for Regression\n",
      "\n",
      "This is page 43\n",
      "Printer: Opaque this\n",
      "3\n",
      "Linear Methods for Regression\n",
      "3.1 Introduction\n",
      "A linear regression model assumes that the regression function E( Y|X) is\n",
      "linear in the inputs X1,... ,X p. Linear models were largely developed in\n",
      "the precomputer age of statistics, but even in today’s computer era there\n",
      "are still good reasons to study and use them. They are simple and often\n",
      "provide an adequate and interpretable description of how the inputs aﬀect\n",
      "the output. For prediction purposes they can sometimes outperform fancier\n",
      "nonlinear models, especially in situations with small numbers of training\n",
      "cases, low signal-to-noise ratio or sparse data. Finally, linear methods can be\n",
      "applied to transformations of the inputs and this considerably expands their\n",
      "scope. These generalizations are sometimes called basis-function methods,\n",
      "and are discussed in Chapter 5.\n",
      "In this chapter we describe linear methods for regression, while in the\n",
      "next chapter we discuss linear methods for classiﬁcation. On some topics we\n",
      "go into considerable detail, as it is our ﬁrm belief that an understanding\n",
      "of linear methods is essential for understanding nonlinear ones. In fact,\n",
      "many nonlinear techniques are direct generalizations of the linear methods\n",
      "discussed here.\n",
      "\n",
      "44 3. Linear Methods for Regression\n",
      "3.2 Linear Regression Models and Least Squares\n",
      "As introduced in Chapter 2, we have an input vector XT= (X1,X2,... ,X p),\n",
      "and want to predict a real-valued output Y. The linear regression model\n",
      "has the form\n",
      "f(X) =β0+p∑\n",
      "j=1Xjβj. (3.1)\n",
      "The linear model either assumes that the regression function E( Y|X) is\n",
      "linear, or that the linear model is a reasonable approximation. Here the\n",
      "βj’s are unknown parameters or coeﬃcients, and the variables Xjcan come\n",
      "from diﬀerent sources:\n",
      "•quantitative inputs;\n",
      "•transformations of quantitative inputs, such as log, square-root or\n",
      "square;\n",
      "•basis expansions, such as X2=X2\n",
      "1,X3=X3\n",
      "1, leading to a polynomial\n",
      "representation;\n",
      "•numeric or “dummy” coding of the levels of qualitative inputs. For\n",
      "example, if Gis a ﬁve-level factor input, we might create Xj, j=\n",
      "1,... ,5,such that Xj=I(G=j). Together this group of Xjrepre-\n",
      "sents the eﬀect of Gby a set of level-dependent constants, since in∑5\n",
      "j=1Xjβj, one of the Xjs is one, and the others are zero.\n",
      "•interactions between variables, for example, X3=X1≤X2.\n",
      "No matter the source of the Xj, the model is linear in the parameters.\n",
      "Typically we have a set of training data ( x1,y1)...(xN,yN) from which\n",
      "to estimate the parameters β. Each xi= (xi1,xi2,... ,x ip)Tis a vector\n",
      "of feature measurements for the ith case. The most popular estimation\n",
      "method is least squares , in which we pick the coeﬃcients β= (β0,β1,... ,β p)T\n",
      "to minimize the residual sum of squares\n",
      "RSS(β) =N∑\n",
      "i=1(yi−f(xi))2\n",
      "=N∑\n",
      "i=1(\n",
      "yi−β0−p∑\n",
      "j=1xijβj)2\n",
      ". (3.2)\n",
      "From a statistical point of view, this criterion is reasonable if the tr aining\n",
      "observations ( xi,yi) represent independent random draws from their popu-\n",
      "lation. Even if the xi’s were not drawn randomly, the criterion is still valid\n",
      "if the yi’s are conditionally independent given the inputs xi. Figure 3.1\n",
      "illustrates the geometry of least-squares ﬁtting in the IRp+1-dimensional\n",
      "\n",
      "94 3. Linear Methods for Regression\n",
      "Bibliographic Notes\n",
      "Linear regression is discussed in many statistics books, for example, Seber\n",
      "(1984), Weisberg (1980) and Mardia et al. (1979). Ridge regression wa s\n",
      "introduced by Hoerl and Kennard (1970), while the lasso was proposed by\n",
      "Tibshirani (1996). Around the same time, lasso-type penalties were pro-\n",
      "posed in the basis pursuit method for signal processing (Chen et al., 1998).\n",
      "The least angle regression procedure was proposed in Efron et al. (2004);\n",
      "related to this is the earlier homotopy procedure of Osborne et al. (2000a)\n",
      "and Osborne et al. (2000b). Their algorithm also exploits the piecewise\n",
      "linearity used in the LAR/lasso algorithm, but lacks its transparency. The\n",
      "criterion for the forward stagewise criterion is discussed in Hastie et a l.\n",
      "(2007). Park and Hastie (2007) develop a path algorithm similar to l east\n",
      "angle regression for generalized regression models. Partial least squares\n",
      "was introduced by Wold (1975). Comparisons of shrinkage methods may\n",
      "be found in Copas (1983) and Frank and Friedman (1993).\n",
      "Exercises\n",
      "Ex. 3.1 Show that the Fstatistic (3.13) for dropping a single coeﬃcient\n",
      "from a model is equal to the square of the corresponding z-score (3.12).\n",
      "Ex. 3.2 Given data on two variables XandY, consider ﬁtting a cubic\n",
      "polynomial regression model f(X) =∑3\n",
      "j=0βjXj. In addition to plotting\n",
      "the ﬁtted curve, you would like a 95% conﬁdence band about the curve.\n",
      "Consider the following two approaches:\n",
      "1. At each point x0, form a 95% conﬁdence interval for the linear func-\n",
      "tionaTβ=∑3\n",
      "j=0βjxj\n",
      "0.\n",
      "2. Form a 95% conﬁdence set for βas in (3.15), which in turn generates\n",
      "conﬁdence intervals for f(x0).\n",
      "How do these approaches diﬀer? Which band is likely to be wider? Conduct\n",
      "a small simulation experiment to compare the two methods.\n",
      "Ex. 3.3 Gauss–Markov theorem:\n",
      "(a) Prove the Gauss–Markov theorem: the least squares estimate of a\n",
      "parameter aTβhas variance no bigger than that of any other linear\n",
      "unbiased estimate of aTβ(Section 3.2.2).\n",
      "(b) The matrix inequality B⪯Aholds if A−Bis positive semideﬁnite.\n",
      "Show that if ˆVis the variance-covariance matrix of the least squares\n",
      "estimate of βand˜Vis the variance-covariance matrix of any other\n",
      "linear unbiased estimate, then ˆV⪯˜V.\n",
      "Human: What is linear regression?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. The linear regression model assumes that the relationship between the variables can be represented by a linear equation. This model aims to find the best-fitting straight line that predicts the dependent variable based on the independent variable(s). The parameters of the linear regression model are estimated using techniques like least squares, where the goal is to minimize the sum of the squared differences between the observed values and the values predicted by the model.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    retriever=index.as_retriever(),\n",
    "    chain_type='stuff',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\n",
    "    'What is linear regression?',\n",
    "    callbacks=[StdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b544f00-5da8-4d93-b7ea-69782100eb61",
   "metadata": {},
   "source": [
    "## The map-reduce chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc430596-c7a2-4570-b46b-fb90867cedb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "100 3. Linear Methods for Regression\n",
      "Human: What is linear regression?\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "This is page 43\n",
      "Printer: Opaque this\n",
      "3\n",
      "Linear Methods for Regression\n",
      "3.1 Introduction\n",
      "A linear regression model assumes that the regression function E( Y|X) is\n",
      "linear in the inputs X1,... ,X p. Linear models were largely developed in\n",
      "the precomputer age of statistics, but even in today’s computer era there\n",
      "are still good reasons to study and use them. They are simple and often\n",
      "provide an adequate and interpretable description of how the inputs aﬀect\n",
      "the output. For prediction purposes they can sometimes outperform fancier\n",
      "nonlinear models, especially in situations with small numbers of training\n",
      "cases, low signal-to-noise ratio or sparse data. Finally, linear methods can be\n",
      "applied to transformations of the inputs and this considerably expands their\n",
      "scope. These generalizations are sometimes called basis-function methods,\n",
      "and are discussed in Chapter 5.\n",
      "In this chapter we describe linear methods for regression, while in the\n",
      "next chapter we discuss linear methods for classiﬁcation. On some topics we\n",
      "go into considerable detail, as it is our ﬁrm belief that an understanding\n",
      "of linear methods is essential for understanding nonlinear ones. In fact,\n",
      "many nonlinear techniques are direct generalizations of the linear methods\n",
      "discussed here.\n",
      "Human: What is linear regression?\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "44 3. Linear Methods for Regression\n",
      "3.2 Linear Regression Models and Least Squares\n",
      "As introduced in Chapter 2, we have an input vector XT= (X1,X2,... ,X p),\n",
      "and want to predict a real-valued output Y. The linear regression model\n",
      "has the form\n",
      "f(X) =β0+p∑\n",
      "j=1Xjβj. (3.1)\n",
      "The linear model either assumes that the regression function E( Y|X) is\n",
      "linear, or that the linear model is a reasonable approximation. Here the\n",
      "βj’s are unknown parameters or coeﬃcients, and the variables Xjcan come\n",
      "from diﬀerent sources:\n",
      "•quantitative inputs;\n",
      "•transformations of quantitative inputs, such as log, square-root or\n",
      "square;\n",
      "•basis expansions, such as X2=X2\n",
      "1,X3=X3\n",
      "1, leading to a polynomial\n",
      "representation;\n",
      "•numeric or “dummy” coding of the levels of qualitative inputs. For\n",
      "example, if Gis a ﬁve-level factor input, we might create Xj, j=\n",
      "1,... ,5,such that Xj=I(G=j). Together this group of Xjrepre-\n",
      "sents the eﬀect of Gby a set of level-dependent constants, since in∑5\n",
      "j=1Xjβj, one of the Xjs is one, and the others are zero.\n",
      "•interactions between variables, for example, X3=X1≤X2.\n",
      "No matter the source of the Xj, the model is linear in the parameters.\n",
      "Typically we have a set of training data ( x1,y1)...(xN,yN) from which\n",
      "to estimate the parameters β. Each xi= (xi1,xi2,... ,x ip)Tis a vector\n",
      "of feature measurements for the ith case. The most popular estimation\n",
      "method is least squares , in which we pick the coeﬃcients β= (β0,β1,... ,β p)T\n",
      "to minimize the residual sum of squares\n",
      "RSS(β) =N∑\n",
      "i=1(yi−f(xi))2\n",
      "=N∑\n",
      "i=1(\n",
      "yi−β0−p∑\n",
      "j=1xijβj)2\n",
      ". (3.2)\n",
      "From a statistical point of view, this criterion is reasonable if the tr aining\n",
      "observations ( xi,yi) represent independent random draws from their popu-\n",
      "lation. Even if the xi’s were not drawn randomly, the criterion is still valid\n",
      "if the yi’s are conditionally independent given the inputs xi. Figure 3.1\n",
      "illustrates the geometry of least-squares ﬁtting in the IRp+1-dimensional\n",
      "Human: What is linear regression?\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "______________________\n",
      "94 3. Linear Methods for Regression\n",
      "Bibliographic Notes\n",
      "Linear regression is discussed in many statistics books, for example, Seber\n",
      "(1984), Weisberg (1980) and Mardia et al. (1979). Ridge regression wa s\n",
      "introduced by Hoerl and Kennard (1970), while the lasso was proposed by\n",
      "Tibshirani (1996). Around the same time, lasso-type penalties were pro-\n",
      "posed in the basis pursuit method for signal processing (Chen et al., 1998).\n",
      "The least angle regression procedure was proposed in Efron et al. (2004);\n",
      "related to this is the earlier homotopy procedure of Osborne et al. (2000a)\n",
      "and Osborne et al. (2000b). Their algorithm also exploits the piecewise\n",
      "linearity used in the LAR/lasso algorithm, but lacks its transparency. The\n",
      "criterion for the forward stagewise criterion is discussed in Hastie et a l.\n",
      "(2007). Park and Hastie (2007) develop a path algorithm similar to l east\n",
      "angle regression for generalized regression models. Partial least squares\n",
      "was introduced by Wold (1975). Comparisons of shrinkage methods may\n",
      "be found in Copas (1983) and Frank and Friedman (1993).\n",
      "Exercises\n",
      "Ex. 3.1 Show that the Fstatistic (3.13) for dropping a single coeﬃcient\n",
      "from a model is equal to the square of the corresponding z-score (3.12).\n",
      "Ex. 3.2 Given data on two variables XandY, consider ﬁtting a cubic\n",
      "polynomial regression model f(X) =∑3\n",
      "j=0βjXj. In addition to plotting\n",
      "the ﬁtted curve, you would like a 95% conﬁdence band about the curve.\n",
      "Consider the following two approaches:\n",
      "1. At each point x0, form a 95% conﬁdence interval for the linear func-\n",
      "tionaTβ=∑3\n",
      "j=0βjxj\n",
      "0.\n",
      "2. Form a 95% conﬁdence set for βas in (3.15), which in turn generates\n",
      "conﬁdence intervals for f(x0).\n",
      "How do these approaches diﬀer? Which band is likely to be wider? Conduct\n",
      "a small simulation experiment to compare the two methods.\n",
      "Ex. 3.3 Gauss–Markov theorem:\n",
      "(a) Prove the Gauss–Markov theorem: the least squares estimate of a\n",
      "parameter aTβhas variance no bigger than that of any other linear\n",
      "unbiased estimate of aTβ(Section 3.2.2).\n",
      "(b) The matrix inequality B⪯Aholds if A−Bis positive semideﬁnite.\n",
      "Show that if ˆVis the variance-covariance matrix of the least squares\n",
      "estimate of βand˜Vis the variance-covariance matrix of any other\n",
      "linear unbiased estimate, then ˆV⪯˜V.\n",
      "Human: What is linear regression?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Given the following extracted parts of a long document and a question, create a final answer. \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "______________________\n",
      "Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data. It is a commonly used technique in regression analysis for predicting the value of the dependent variable based on the values of the independent variables.\n",
      "\n",
      "Linear regression is a statistical method that assumes the relationship between the dependent variable (Y) and one or more independent variables (X) is linear. This means that the regression function E(Y|X) is linear in the inputs X1,...,Xp. Linear regression models were developed before the computer age, but they are still widely used today because they are simple, interpretable, and can sometimes outperform more complex nonlinear models, especially in situations with small amounts of training data, low signal-to-noise ratio, or sparse data. Additionally, linear methods can be applied to transformations of the inputs, which expands their scope.\n",
      "\n",
      "Linear regression is a statistical method used to model the relationship between a dependent variable (often denoted as Y) and one or more independent variables (often denoted as X). In linear regression, the relationship between the variables is assumed to be linear, and the goal is to find the best-fitting line or plane that minimizes the sum of squared differences between the observed values and the values predicted by the model. The equation for a simple linear regression model with one independent variable is typically represented as Y = β0 + β1X + ε, where Y is the dependent variable, X is the independent variable, β0 and β1 are coefficients, and ε represents the error term. The coefficients are estimated using methods like least squares, where the sum of squared residuals is minimized to find the best-fitting line.\n",
      "\n",
      "Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data. This method assumes that the relationship between the variables can be approximated by a straight line. The goal of linear regression is to find the best-fitting line that describes the relationship between the variables, allowing for predictions or explanations based on this relationship. It is a fundamental technique in statistical modeling and is extensively discussed in various statistics books and research articles.\n",
      "Human: What is linear regression?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data. It assumes that the relationship between the variables is linear and aims to find the best-fitting line that describes this relationship.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=index.as_retriever(),\n",
    "    chain_type='map_reduce',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\n",
    "    'What is linear regression?',\n",
    "    callbacks=[StdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34b6a9-16a3-48b8-814e-8a93b98f9491",
   "metadata": {},
   "source": [
    "## The refine strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e075749b-9322-4556-971a-34ba7cbd6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Context information is below.\n",
      "------------\n",
      "100 3. Linear Methods for Regression\n",
      "------------\n",
      "Given the context information and not prior knowledge, answer any questions\n",
      "Human: What is linear regression?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: What is linear regression?\n",
      "AI: Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data. The goal of linear regression is to find the best-fitting line that represents the relationship between the variables, allowing us to make predictions or understand the impact of the independent variables on the dependent variable.\n",
      "Human: We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "This is page 43\n",
      "Printer: Opaque this\n",
      "3\n",
      "Linear Methods for Regression\n",
      "3.1 Introduction\n",
      "A linear regression model assumes that the regression function E( Y|X) is\n",
      "linear in the inputs X1,... ,X p. Linear models were largely developed in\n",
      "the precomputer age of statistics, but even in today’s computer era there\n",
      "are still good reasons to study and use them. They are simple and often\n",
      "provide an adequate and interpretable description of how the inputs aﬀect\n",
      "the output. For prediction purposes they can sometimes outperform fancier\n",
      "nonlinear models, especially in situations with small numbers of training\n",
      "cases, low signal-to-noise ratio or sparse data. Finally, linear methods can be\n",
      "applied to transformations of the inputs and this considerably expands their\n",
      "scope. These generalizations are sometimes called basis-function methods,\n",
      "and are discussed in Chapter 5.\n",
      "In this chapter we describe linear methods for regression, while in the\n",
      "next chapter we discuss linear methods for classiﬁcation. On some topics we\n",
      "go into considerable detail, as it is our ﬁrm belief that an understanding\n",
      "of linear methods is essential for understanding nonlinear ones. In fact,\n",
      "many nonlinear techniques are direct generalizations of the linear methods\n",
      "discussed here.\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: What is linear regression?\n",
      "AI: Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data. It assumes that the regression function is linear in the inputs X1, X2,... ,Xp. Linear models are simple and provide an interpretable description of how the inputs affect the output. They can outperform fancier nonlinear models in situations with small training cases, low signal-to-noise ratio, or sparse data. Linear methods can be applied to transformations of the inputs, expanding their scope through basis-function methods, as discussed in Chapter 5 of linear methods for regression. Understanding linear methods is considered essential for grasping nonlinear techniques, as many nonlinear techniques are direct generalizations of linear methods.\n",
      "Human: We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "44 3. Linear Methods for Regression\n",
      "3.2 Linear Regression Models and Least Squares\n",
      "As introduced in Chapter 2, we have an input vector XT= (X1,X2,... ,X p),\n",
      "and want to predict a real-valued output Y. The linear regression model\n",
      "has the form\n",
      "f(X) =β0+p∑\n",
      "j=1Xjβj. (3.1)\n",
      "The linear model either assumes that the regression function E( Y|X) is\n",
      "linear, or that the linear model is a reasonable approximation. Here the\n",
      "βj’s are unknown parameters or coeﬃcients, and the variables Xjcan come\n",
      "from diﬀerent sources:\n",
      "•quantitative inputs;\n",
      "•transformations of quantitative inputs, such as log, square-root or\n",
      "square;\n",
      "•basis expansions, such as X2=X2\n",
      "1,X3=X3\n",
      "1, leading to a polynomial\n",
      "representation;\n",
      "•numeric or “dummy” coding of the levels of qualitative inputs. For\n",
      "example, if Gis a ﬁve-level factor input, we might create Xj, j=\n",
      "1,... ,5,such that Xj=I(G=j). Together this group of Xjrepre-\n",
      "sents the eﬀect of Gby a set of level-dependent constants, since in∑5\n",
      "j=1Xjβj, one of the Xjs is one, and the others are zero.\n",
      "•interactions between variables, for example, X3=X1≤X2.\n",
      "No matter the source of the Xj, the model is linear in the parameters.\n",
      "Typically we have a set of training data ( x1,y1)...(xN,yN) from which\n",
      "to estimate the parameters β. Each xi= (xi1,xi2,... ,x ip)Tis a vector\n",
      "of feature measurements for the ith case. The most popular estimation\n",
      "method is least squares , in which we pick the coeﬃcients β= (β0,β1,... ,β p)T\n",
      "to minimize the residual sum of squares\n",
      "RSS(β) =N∑\n",
      "i=1(yi−f(xi))2\n",
      "=N∑\n",
      "i=1(\n",
      "yi−β0−p∑\n",
      "j=1xijβj)2\n",
      ". (3.2)\n",
      "From a statistical point of view, this criterion is reasonable if the tr aining\n",
      "observations ( xi,yi) represent independent random draws from their popu-\n",
      "lation. Even if the xi’s were not drawn randomly, the criterion is still valid\n",
      "if the yi’s are conditionally independent given the inputs xi. Figure 3.1\n",
      "illustrates the geometry of least-squares ﬁtting in the IRp+1-dimensional\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: What is linear regression?\n",
      "AI: Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data. The linear regression model assumes that the regression function is linear in the inputs X1, X2,... ,Xp. The model has the form f(X) = β0 + ∑(j=1 to p) Xjβj. The parameters βj represent unknown coefficients, and the variables Xj can come from various sources such as quantitative inputs, transformations of quantitative inputs, basis expansions, numeric or \"dummy\" coding of qualitative inputs, and interactions between variables.\n",
      "\n",
      "To estimate the parameters β, least squares is the most popular method used in linear regression. The goal is to minimize the residual sum of squares (RSS) by choosing the coefficients that best fit the training data. This method is valid if the training observations are independent random draws from their population or if the dependent variables are conditionally independent given the inputs. Linear regression is widely used in statistical modeling to understand and predict relationships between variables.\n",
      "Human: We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "94 3. Linear Methods for Regression\n",
      "Bibliographic Notes\n",
      "Linear regression is discussed in many statistics books, for example, Seber\n",
      "(1984), Weisberg (1980) and Mardia et al. (1979). Ridge regression wa s\n",
      "introduced by Hoerl and Kennard (1970), while the lasso was proposed by\n",
      "Tibshirani (1996). Around the same time, lasso-type penalties were pro-\n",
      "posed in the basis pursuit method for signal processing (Chen et al., 1998).\n",
      "The least angle regression procedure was proposed in Efron et al. (2004);\n",
      "related to this is the earlier homotopy procedure of Osborne et al. (2000a)\n",
      "and Osborne et al. (2000b). Their algorithm also exploits the piecewise\n",
      "linearity used in the LAR/lasso algorithm, but lacks its transparency. The\n",
      "criterion for the forward stagewise criterion is discussed in Hastie et a l.\n",
      "(2007). Park and Hastie (2007) develop a path algorithm similar to l east\n",
      "angle regression for generalized regression models. Partial least squares\n",
      "was introduced by Wold (1975). Comparisons of shrinkage methods may\n",
      "be found in Copas (1983) and Frank and Friedman (1993).\n",
      "Exercises\n",
      "Ex. 3.1 Show that the Fstatistic (3.13) for dropping a single coeﬃcient\n",
      "from a model is equal to the square of the corresponding z-score (3.12).\n",
      "Ex. 3.2 Given data on two variables XandY, consider ﬁtting a cubic\n",
      "polynomial regression model f(X) =∑3\n",
      "j=0βjXj. In addition to plotting\n",
      "the ﬁtted curve, you would like a 95% conﬁdence band about the curve.\n",
      "Consider the following two approaches:\n",
      "1. At each point x0, form a 95% conﬁdence interval for the linear func-\n",
      "tionaTβ=∑3\n",
      "j=0βjxj\n",
      "0.\n",
      "2. Form a 95% conﬁdence set for βas in (3.15), which in turn generates\n",
      "conﬁdence intervals for f(x0).\n",
      "How do these approaches diﬀer? Which band is likely to be wider? Conduct\n",
      "a small simulation experiment to compare the two methods.\n",
      "Ex. 3.3 Gauss–Markov theorem:\n",
      "(a) Prove the Gauss–Markov theorem: the least squares estimate of a\n",
      "parameter aTβhas variance no bigger than that of any other linear\n",
      "unbiased estimate of aTβ(Section 3.2.2).\n",
      "(b) The matrix inequality B⪯Aholds if A−Bis positive semideﬁnite.\n",
      "Show that if ˆVis the variance-covariance matrix of the least squares\n",
      "estimate of βand˜Vis the variance-covariance matrix of any other\n",
      "linear unbiased estimate, then ˆV⪯˜V.\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The additional context provided does not require any changes to the original answer.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=index.as_retriever(),\n",
    "    chain_type='refine',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\n",
    "    'What is linear regression?',\n",
    "    callbacks=[StdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b799546-1d48-4a78-8d08-b6f084a2d8f0",
   "metadata": {},
   "source": [
    "## The map-rerank strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e05fd3-d248-40fc-89c1-617818402f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MapRerankDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "100 3. Linear Methods for Regression\n",
      "---------\n",
      "Question: What is linear regression?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "This is page 43\n",
      "Printer: Opaque this\n",
      "3\n",
      "Linear Methods for Regression\n",
      "3.1 Introduction\n",
      "A linear regression model assumes that the regression function E( Y|X) is\n",
      "linear in the inputs X1,... ,X p. Linear models were largely developed in\n",
      "the precomputer age of statistics, but even in today’s computer era there\n",
      "are still good reasons to study and use them. They are simple and often\n",
      "provide an adequate and interpretable description of how the inputs aﬀect\n",
      "the output. For prediction purposes they can sometimes outperform fancier\n",
      "nonlinear models, especially in situations with small numbers of training\n",
      "cases, low signal-to-noise ratio or sparse data. Finally, linear methods can be\n",
      "applied to transformations of the inputs and this considerably expands their\n",
      "scope. These generalizations are sometimes called basis-function methods,\n",
      "and are discussed in Chapter 5.\n",
      "In this chapter we describe linear methods for regression, while in the\n",
      "next chapter we discuss linear methods for classiﬁcation. On some topics we\n",
      "go into considerable detail, as it is our ﬁrm belief that an understanding\n",
      "of linear methods is essential for understanding nonlinear ones. In fact,\n",
      "many nonlinear techniques are direct generalizations of the linear methods\n",
      "discussed here.\n",
      "---------\n",
      "Question: What is linear regression?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "44 3. Linear Methods for Regression\n",
      "3.2 Linear Regression Models and Least Squares\n",
      "As introduced in Chapter 2, we have an input vector XT= (X1,X2,... ,X p),\n",
      "and want to predict a real-valued output Y. The linear regression model\n",
      "has the form\n",
      "f(X) =β0+p∑\n",
      "j=1Xjβj. (3.1)\n",
      "The linear model either assumes that the regression function E( Y|X) is\n",
      "linear, or that the linear model is a reasonable approximation. Here the\n",
      "βj’s are unknown parameters or coeﬃcients, and the variables Xjcan come\n",
      "from diﬀerent sources:\n",
      "•quantitative inputs;\n",
      "•transformations of quantitative inputs, such as log, square-root or\n",
      "square;\n",
      "•basis expansions, such as X2=X2\n",
      "1,X3=X3\n",
      "1, leading to a polynomial\n",
      "representation;\n",
      "•numeric or “dummy” coding of the levels of qualitative inputs. For\n",
      "example, if Gis a ﬁve-level factor input, we might create Xj, j=\n",
      "1,... ,5,such that Xj=I(G=j). Together this group of Xjrepre-\n",
      "sents the eﬀect of Gby a set of level-dependent constants, since in∑5\n",
      "j=1Xjβj, one of the Xjs is one, and the others are zero.\n",
      "•interactions between variables, for example, X3=X1≤X2.\n",
      "No matter the source of the Xj, the model is linear in the parameters.\n",
      "Typically we have a set of training data ( x1,y1)...(xN,yN) from which\n",
      "to estimate the parameters β. Each xi= (xi1,xi2,... ,x ip)Tis a vector\n",
      "of feature measurements for the ith case. The most popular estimation\n",
      "method is least squares , in which we pick the coeﬃcients β= (β0,β1,... ,β p)T\n",
      "to minimize the residual sum of squares\n",
      "RSS(β) =N∑\n",
      "i=1(yi−f(xi))2\n",
      "=N∑\n",
      "i=1(\n",
      "yi−β0−p∑\n",
      "j=1xijβj)2\n",
      ". (3.2)\n",
      "From a statistical point of view, this criterion is reasonable if the tr aining\n",
      "observations ( xi,yi) represent independent random draws from their popu-\n",
      "lation. Even if the xi’s were not drawn randomly, the criterion is still valid\n",
      "if the yi’s are conditionally independent given the inputs xi. Figure 3.1\n",
      "illustrates the geometry of least-squares ﬁtting in the IRp+1-dimensional\n",
      "---------\n",
      "Question: What is linear regression?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "94 3. Linear Methods for Regression\n",
      "Bibliographic Notes\n",
      "Linear regression is discussed in many statistics books, for example, Seber\n",
      "(1984), Weisberg (1980) and Mardia et al. (1979). Ridge regression wa s\n",
      "introduced by Hoerl and Kennard (1970), while the lasso was proposed by\n",
      "Tibshirani (1996). Around the same time, lasso-type penalties were pro-\n",
      "posed in the basis pursuit method for signal processing (Chen et al., 1998).\n",
      "The least angle regression procedure was proposed in Efron et al. (2004);\n",
      "related to this is the earlier homotopy procedure of Osborne et al. (2000a)\n",
      "and Osborne et al. (2000b). Their algorithm also exploits the piecewise\n",
      "linearity used in the LAR/lasso algorithm, but lacks its transparency. The\n",
      "criterion for the forward stagewise criterion is discussed in Hastie et a l.\n",
      "(2007). Park and Hastie (2007) develop a path algorithm similar to l east\n",
      "angle regression for generalized regression models. Partial least squares\n",
      "was introduced by Wold (1975). Comparisons of shrinkage methods may\n",
      "be found in Copas (1983) and Frank and Friedman (1993).\n",
      "Exercises\n",
      "Ex. 3.1 Show that the Fstatistic (3.13) for dropping a single coeﬃcient\n",
      "from a model is equal to the square of the corresponding z-score (3.12).\n",
      "Ex. 3.2 Given data on two variables XandY, consider ﬁtting a cubic\n",
      "polynomial regression model f(X) =∑3\n",
      "j=0βjXj. In addition to plotting\n",
      "the ﬁtted curve, you would like a 95% conﬁdence band about the curve.\n",
      "Consider the following two approaches:\n",
      "1. At each point x0, form a 95% conﬁdence interval for the linear func-\n",
      "tionaTβ=∑3\n",
      "j=0βjxj\n",
      "0.\n",
      "2. Form a 95% conﬁdence set for βas in (3.15), which in turn generates\n",
      "conﬁdence intervals for f(x0).\n",
      "How do these approaches diﬀer? Which band is likely to be wider? Conduct\n",
      "a small simulation experiment to compare the two methods.\n",
      "Ex. 3.3 Gauss–Markov theorem:\n",
      "(a) Prove the Gauss–Markov theorem: the least squares estimate of a\n",
      "parameter aTβhas variance no bigger than that of any other linear\n",
      "unbiased estimate of aTβ(Section 3.2.2).\n",
      "(b) The matrix inequality B⪯Aholds if A−Bis positive semideﬁnite.\n",
      "Show that if ˆVis the variance-covariance matrix of the least squares\n",
      "estimate of βand˜Vis the variance-covariance matrix of any other\n",
      "linear unbiased estimate, then ˆV⪯˜V.\n",
      "---------\n",
      "Question: What is linear regression?\n",
      "Helpful Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain\\chains\\llm.py:367: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data. This method is commonly used for predicting future values based on past data. '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=index.as_retriever(),\n",
    "    chain_type='map_rerank',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\n",
    "    'What is linear regression?',\n",
    "    callbacks=[StdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c6233-d31a-4ab4-a38d-2d301bc3edfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
